{
  "id": "46f0b708-7a4b-453b-8c0e-d57f9f304265",
  "name": "Salad Cloud",
  "slug": "salad",
  "description": "Salad Cloud is a distributed GPU platform that runs containers across community-powered GPUs and secure data center clusters, advertising pricing as low as $0.02/hr and sub-$1/hr H100 NVL capacity.",
  "link": "https://salad.com",
  "docsLink": "https://docs.salad.com",
  "features": [
    {
      "title": "Community GPU Pool",
      "description": "Community-powered GPUs for stateless and high-volume workloads with pricing advertised from $0.02/hr per GPU."
    },
    {
      "title": "Secure GPU Clusters",
      "description": "Data center-grade A100, L40S, and H100 NVL capacity with managed orchestration for compliant workloads."
    },
    {
      "title": "Managed Container Engine",
      "description": "Deploy containers without managing nodes; scale replicas across thousands of GPUs via the Salad portal."
    },
    {
      "title": "Published Hourly Rates",
      "description": "Pricing calculator lists L40S at $0.32/hr, A100 80 GB at $0.50/hr, A100 40 GB at $0.40/hr, and H100 NVL at $0.99/hr per GPU."
    },
    {
      "title": "Developer Hub & Docs",
      "description": "Portal access, Developer Hub, and product documentation at docs.salad.com."
    }
  ],
  "pros": [
    "Very low published GPU pricing, including sub-$1/hr H100 NVL and $0.02/hr community options",
    "Mix of community GPUs and secure data center clusters with A100/L40S/H100 options",
    "Managed container engine reduces infrastructure and orchestration overhead",
    "Developer portal, calculator, and docs make costs and deployment steps clear"
  ],
  "cons": [
    "Community GPU pool is best for stateless or fault-tolerant workloads where node variability is acceptable",
    "Secure tier GPU lineup is limited to the published SKUs (H100 NVL, A100, L40S) and 8x cluster configurations"
  ],
  "gettingStarted": [
    {
      "title": "Create a SaladCloud account",
      "description": "Sign up and log in at portal.salad.com to access the dashboard and calculator."
    },
    {
      "title": "Choose a container engine tier",
      "description": "Pick Community for the lowest-cost consumer GPUs or Secure for data center-grade H100/A100/L40S clusters."
    },
    {
      "title": "Select GPU type and replicas",
      "description": "Use the pricing calculator to pick a GPU SKU (e.g., L40S, A100, H100 NVL) and set the number of replicas."
    },
    {
      "title": "Deploy your container",
      "description": "Provide your image, command, and environment settings, then launch via the portal or API."
    },
    {
      "title": "Monitor and iterate",
      "description": "Track deployments and status in the portal; adjust replicas or GPU class as needed."
    }
  ],
  "computeServices": [
    {
      "name": "Salad Container Engine - Secure",
      "description": "Managed container orchestration on data center GPUs such as H100 NVL, A100, and L40S with pricing shown under $1/hr per GPU.",
      "instanceTypes": [
        {
          "name": "H100 NVL (94 GB)",
          "description": "Secure clusters of H100 NVL GPUs for high-performance training or inference.",
          "features": [
            "Published at $0.99/hr per GPU in the pricing calculator",
            "Offered in 8x GPU cluster configurations",
            "Managed orchestration with autoscaling via the portal"
          ]
        },
        {
          "name": "A100 80 GB SXM",
          "description": "A100 80 GB GPUs for dense AI workloads.",
          "features": [
            "Listed at $0.50/hr per GPU",
            "Suitable for training and large-batch inference",
            "Runs on secure, data center-grade hosts"
          ]
        },
        {
          "name": "A100 40 GB PCIe",
          "description": "A100 40 GB GPUs with secure cluster orchestration.",
          "features": [
            "$0.40/hr per GPU published pricing",
            "Good for balanced training and inference workloads"
          ]
        },
        {
          "name": "L40S (48 GB)",
          "description": "Ada Lovelace L40S GPUs for inference and graphics-heavy tasks.",
          "features": [
            "$0.32/hr per GPU listed pricing",
            "Managed scaling via the Secure container engine"
          ]
        }
      ]
    },
    {
      "name": "Salad Container Engine - Community",
      "description": "Community-powered GPU pool for flexible, stateless workloads with headline pricing from $0.02/hr per GPU.",
      "instanceTypes": [
        {
          "name": "RTX 5090 (32 GB)",
          "description": "High-end consumer GPUs for fast inference or rendering.",
          "features": [
            "$0.25/hr per GPU on the pricing calculator",
            "Best for cost-sensitive inference and graphics jobs"
          ]
        },
        {
          "name": "RTX A5000 (24 GB)",
          "description": "Midrange consumer GPU option for budget-friendly deployment.",
          "features": [
            "$0.09/hr per GPU published pricing",
            "Ideal for batch jobs and lower-latency inference at low cost"
          ]
        }
      ]
    }
  ],
  "gpuServices": [
    {
      "name": "GPU Catalog",
      "description": "Mix of community and secure GPU SKUs with transparent hourly pricing.",
      "types": [
        {
          "name": "H100 NVL",
          "gpuModel": "NVIDIA H100 NVL 94 GB",
          "bestFor": "High-throughput training and inference on secure clusters"
        },
        {
          "name": "A100 80 GB",
          "gpuModel": "NVIDIA A100 80 GB SXM",
          "bestFor": "Training and larger batch inference on managed clusters"
        },
        {
          "name": "A100 40 GB",
          "gpuModel": "NVIDIA A100 40 GB PCIe",
          "bestFor": "Balanced AI workloads on secure infrastructure"
        },
        {
          "name": "L40S",
          "gpuModel": "NVIDIA L40S 48 GB",
          "bestFor": "Cost-efficient inference, graphics, and media workloads"
        },
        {
          "name": "RTX 5090",
          "gpuModel": "NVIDIA RTX 5090 32 GB",
          "bestFor": "Fast community GPUs for inference and rendering"
        },
        {
          "name": "RTX A5000",
          "gpuModel": "NVIDIA RTX A5000 24 GB",
          "bestFor": "Budget-friendly inference and batch processing"
        }
      ]
    }
  ],
  "pricingOptions": [
    {
      "name": "Community GPUs from $0.02/hr",
      "description": "Community tier advertises GPU pricing starting at $0.02/hr for stateless workloads."
    },
    {
      "name": "Consumer GPU hourly rates",
      "description": "Pricing calculator lists RTX A5000 at $0.09/hr and RTX 5090 at $0.25/hr per GPU."
    },
    {
      "name": "Secure tier hourly rates",
      "description": "Published secure pricing includes L40S at $0.32/hr, A100 40 GB at $0.40/hr, A100 80 GB at $0.50/hr, and H100 NVL at $0.99/hr per GPU (8x clusters)."
    },
    {
      "name": "On-demand, no contracts",
      "description": "Hourly billing via the Salad portal and calculator with no prepayments required."
    }
  ],
  "regions": "Distributed global community GPU network with secure data center clusters (locations not explicitly listed on public pages).",
  "support": "Documentation and Developer Hub at docs.salad.com, portal dashboards with a status page, community Discord, and sales contact for secure clusters.",
  "uniqueSellingPoints": [
    "Combines a community GPU pool with secure data center clusters under one container engine",
    "Publishes very low hourly rates, including sub-$1/hr H100 NVL and $0.02/hr community options",
    "Fully managed container orchestration so users deploy images without handling node management"
  ],
  "hqCountry": "US",
  "tagline": "Distributed cloud powered by consumer GPUs",
  "tags": [
    "Budget",
    "Decentralized"
  ],
  "category": "DC aggregator"
}
