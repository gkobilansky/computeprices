{
  "id": "46f0b708-7a4b-453b-8c0e-d57f9f304265",
  "name": "Salad Cloud",
  "slug": "salad",
  "description": "Salad Cloud is a distributed GPU platform that runs containers across community-powered GPUs and secure data center clusters, offering competitive pricing for both consumer and data center GPUs.",
  "link": "https://salad.com",
  "docsLink": "https://docs.salad.com",
  "features": [
    {
      "title": "Community GPU Pool",
      "description": "Community-powered consumer GPUs for stateless and high-volume workloads with very competitive pricing."
    },
    {
      "title": "Secure GPU Clusters",
      "description": "Data center-grade A100, L40S, and H100 NVL capacity with managed orchestration for compliant workloads."
    },
    {
      "title": "Managed Container Engine",
      "description": "Deploy containers without managing nodes; scale replicas across thousands of GPUs via the Salad portal."
    },
    {
      "title": "Transparent Pricing Calculator",
      "description": "Public pricing calculator shows hourly rates for all GPU types across both Community and Secure tiers."
    },
    {
      "title": "Developer Hub & Docs",
      "description": "Portal access, Developer Hub, and product documentation at docs.salad.com."
    }
  ],
  "pros": [
    "Very competitive GPU pricing across both community and secure tiers",
    "Mix of community GPUs and secure data center clusters with A100/L40S/H100 options",
    "Managed container engine reduces infrastructure and orchestration overhead",
    "Developer portal, calculator, and docs make costs and deployment steps clear",
    "Transparent pricing calculator with published rates for all GPU types"
  ],
  "cons": [
    "Community GPU pool is best for stateless or fault-tolerant workloads where node variability is acceptable",
    "Secure tier GPU lineup is limited to the published SKUs (H100 NVL, A100, L40S) and 8x cluster configurations"
  ],
  "gettingStarted": [
    {
      "title": "Create a SaladCloud account",
      "description": "Sign up and log in at portal.salad.com to access the dashboard and calculator."
    },
    {
      "title": "Choose a container engine tier",
      "description": "Pick Community for the lowest-cost consumer GPUs or Secure for data center-grade H100/A100/L40S clusters."
    },
    {
      "title": "Select GPU type and replicas",
      "description": "Use the pricing calculator to pick a GPU SKU (e.g., L40S, A100, H100 NVL) and set the number of replicas."
    },
    {
      "title": "Deploy your container",
      "description": "Provide your image, command, and environment settings, then launch via the portal or API."
    },
    {
      "title": "Monitor and iterate",
      "description": "Track deployments and status in the portal; adjust replicas or GPU class as needed."
    }
  ],
  "computeServices": [
    {
      "name": "Salad Container Engine - Secure",
      "description": "Managed container orchestration on data center GPUs such as H100 NVL, A100, and L40S with competitive hourly pricing.",
      "instanceTypes": [
        {
          "name": "H100 NVL (94 GB)",
          "description": "Secure clusters of H100 NVL GPUs for high-performance training or inference.",
          "features": [
            "Offered in 8x GPU cluster configurations",
            "Managed orchestration with autoscaling via the portal",
            "Data center-grade reliability and security"
          ]
        },
        {
          "name": "A100 80 GB SXM",
          "description": "A100 80 GB GPUs for dense AI workloads.",
          "features": [
            "Suitable for training and large-batch inference",
            "Runs on secure, data center-grade hosts",
            "NVLink support for multi-GPU communication"
          ]
        },
        {
          "name": "A100 40 GB PCIe",
          "description": "A100 40 GB GPUs with secure cluster orchestration.",
          "features": [
            "Good for balanced training and inference workloads",
            "Enterprise-grade data center infrastructure"
          ]
        },
        {
          "name": "L40S (48 GB)",
          "description": "Ada Lovelace L40S GPUs for inference and graphics-heavy tasks.",
          "features": [
            "Managed scaling via the Secure container engine",
            "Ideal for AI inference and visual computing"
          ]
        }
      ]
    },
    {
      "name": "Salad Container Engine - Community",
      "description": "Community-powered GPU pool for flexible, stateless workloads with very competitive pricing.",
      "instanceTypes": [
        {
          "name": "RTX 5090 (32 GB)",
          "description": "High-end consumer GPUs for fast inference or rendering.",
          "features": [
            "Best for cost-sensitive inference and graphics jobs",
            "Wide availability across community network"
          ]
        },
        {
          "name": "RTX A5000 (24 GB)",
          "description": "Midrange consumer GPU option for budget-friendly deployment.",
          "features": [
            "Ideal for batch jobs and lower-latency inference",
            "Extremely cost-effective for fault-tolerant workloads"
          ]
        }
      ]
    }
  ],
  "gpuServices": [
    {
      "name": "GPU Catalog",
      "description": "Mix of community and secure GPU SKUs with transparent hourly pricing.",
      "types": [
        {
          "name": "H100 NVL",
          "gpuModel": "NVIDIA H100 NVL 94 GB",
          "bestFor": "High-throughput training and inference on secure clusters"
        },
        {
          "name": "A100 80 GB",
          "gpuModel": "NVIDIA A100 80 GB SXM",
          "bestFor": "Training and larger batch inference on managed clusters"
        },
        {
          "name": "A100 40 GB",
          "gpuModel": "NVIDIA A100 40 GB PCIe",
          "bestFor": "Balanced AI workloads on secure infrastructure"
        },
        {
          "name": "L40S",
          "gpuModel": "NVIDIA L40S 48 GB",
          "bestFor": "Cost-efficient inference, graphics, and media workloads"
        },
        {
          "name": "RTX 5090",
          "gpuModel": "NVIDIA RTX 5090 32 GB",
          "bestFor": "Fast community GPUs for inference and rendering"
        },
        {
          "name": "RTX A5000",
          "gpuModel": "NVIDIA RTX A5000 24 GB",
          "bestFor": "Budget-friendly inference and batch processing"
        }
      ]
    }
  ],
  "pricingOptions": [
    {
      "name": "Community GPU Pricing",
      "description": "Extremely cost-effective community tier with consumer GPUs for stateless and fault-tolerant workloads."
    },
    {
      "name": "Secure Tier Pricing",
      "description": "Competitive hourly rates for data center-grade H100 NVL, A100, and L40S GPUs with managed orchestration."
    },
    {
      "name": "On-demand, no contracts",
      "description": "Hourly billing via the Salad portal and calculator with no prepayments or long-term commitments required."
    },
    {
      "name": "Transparent pricing calculator",
      "description": "Public pricing calculator available showing all GPU types and hourly rates across both tiers."
    }
  ],
  "regions": "Distributed global community GPU network with secure data center clusters (locations not explicitly listed on public pages).",
  "support": "Documentation and Developer Hub at docs.salad.com, portal dashboards with a status page, community Discord, and sales contact for secure clusters.",
  "uniqueSellingPoints": [
    "Combines a community GPU pool with secure data center clusters under one container engine",
    "Highly competitive pricing across both community consumer GPUs and data center GPUs",
    "Fully managed container orchestration so users deploy images without handling node management",
    "Transparent pricing calculator with published rates for all GPU types"
  ],
  "hqCountry": "US",
  "tagline": "Distributed cloud powered by consumer GPUs",
  "tags": [
    "Budget",
    "Decentralized"
  ],
  "category": "DC aggregator"
}
