[
  {
    "id": "3bb5a379-472f-4c84-9ba4-3337f3922582",
    "name": "Amazon AWS",
    "slug": "aws",
    "description": "AWS provides a comprehensive suite of cloud computing services, including compute, storage, and GPU solutions for diverse workloads.",
    "link": "https://aws.amazon.com",
    "docsLink": "https://docs.aws.amazon.com",
    "features": [
      {
        "title": "Global Infrastructure",
        "description": "Extensive network of data centers across multiple regions worldwide"
      },
      {
        "title": "Pay-as-you-go Pricing",
        "description": "Flexible pricing model with no upfront commitments required"
      },
      {
        "title": "Advanced Security",
        "description": "Comprehensive security tools and compliance certifications"
      },
      {
        "title": "Auto Scaling",
        "description": "Automatically adjust resources based on demand"
      },
      {
        "title": "Integrated Services",
        "description": "Extensive ecosystem of services that work seamlessly together"
      },
      {
        "title": "Developer Tools",
        "description": "Comprehensive suite of tools for development, deployment, and management"
      }
    ],
    "pros": [
      "Broad range of compute options including GPUs",
      "Highly scalable and reliable infrastructure",
      "Pay-as-you-go pricing with cost optimization tools",
      "Extensive global network of data centers",
      "Rich ecosystem of integrated services and tools"
    ],
    "cons": [
      "Complex pricing structure",
      "Steep learning curve for new users",
      "Potential for unexpected costs without proper management"
    ],
    "gettingStarted": [
      {
        "title": "Sign up for AWS",
        "description": "Create an AWS account to access the cloud platform."
      },
      {
        "title": "Choose a compute service",
        "description": "Select from EC2, Lambda, or container services based on your workload needs."
      },
      {
        "title": "Launch an instance",
        "description": "Configure and launch your first compute instance or container."
      },
      {
        "title": "Set up security",
        "description": "Configure security groups and access controls for your resources."
      },
      {
        "title": "Monitor and optimize",
        "description": "Use AWS CloudWatch and Compute Optimizer to monitor performance and reduce costs."
      }
    ],
    "computeServices": [
      {
        "name": "Amazon EC2",
        "description": "Virtual servers in the cloud with a wide range of instance types.",
        "instanceTypes": [
          {
            "name": "P4 Instances",
            "description": "Powered by NVIDIA A100 Tensor Core GPUs, optimized for AI and HPC workloads.",
            "features": [
              "Up to 8 NVIDIA A100 GPUs per instance",
              "600 GB/s GPU-to-GPU bandwidth with NVSwitch",
              "Elastic Fabric Adapter (EFA) for low-latency, multi-node GPU training",
              "Network throughput of up to 400 Gbps"
            ]
          },
          {
            "name": "P3 Instances",
            "description": "Equipped with NVIDIA V100 Tensor Core GPUs for deep learning and HPC.",
            "features": [
              "Up to 8 NVIDIA V100 GPUs per instance",
              "300 GB/s GPU-to-GPU bandwidth with NVLink",
              "Suitable for FP16 and FP32 precision workloads"
            ]
          },
          {
            "name": "G5 Instances",
            "description": "Powered by NVIDIA A10G GPUs for graphics-intensive applications.",
            "features": [
              "Optimized for real-time ray tracing and AI-driven graphics",
              "Suitable for game streaming and content creation"
            ]
          }
        ]
      },
      {
        "name": "Amazon ECS",
        "description": "Fully managed container orchestration service.",
        "features": [
          "Support for Docker containers",
          "Integration with other AWS services",
          "Automated cluster management and scheduling"
        ]
      },
      {
        "name": "Amazon EKS",
        "description": "Managed Kubernetes service for container orchestration.",
        "features": [
          "Certified Kubernetes conformant",
          "Integrates with AWS networking and security services",
          "Supports both EC2 and Fargate launch types"
        ]
      },
      {
        "name": "AWS Lambda",
        "description": "Serverless compute service for running code without managing servers.",
        "features": [
          "Automatic scaling and high availability",
          "Pay only for compute time consumed",
          "Supports multiple programming languages"
        ]
      }
    ],
    "gpuServices": [
      {
        "name": "EC2 GPU Instances",
        "description": "EC2 instances equipped with powerful GPUs for compute-intensive workloads.",
        "types": [
          {
            "name": "P4 Instances",
            "gpuModel": "NVIDIA A100 Tensor Core",
            "bestFor": "Large-scale AI training, HPC simulations"
          },
          {
            "name": "P3 Instances",
            "gpuModel": "NVIDIA V100 Tensor Core",
            "bestFor": "Deep learning training and inference, scientific simulations"
          },
          {
            "name": "G5 Instances",
            "gpuModel": "NVIDIA A10G",
            "bestFor": "Graphics rendering, game streaming, machine learning inference"
          }
        ]
      },
      {
        "name": "Amazon SageMaker",
        "description": "Fully managed machine learning platform with GPU support.",
        "features": [
          "Integrated Jupyter notebooks with GPU acceleration",
          "Automated model tuning and deployment",
          "Built-in algorithms optimized for GPU execution"
        ]
      }
    ],
    "pricingOptions": [
      {
        "name": "On-Demand Instances",
        "description": "Pay for compute capacity by the second with no long-term commitments."
      },
      {
        "name": "Spot Instances",
        "description": "Use spare EC2 capacity at up to 90% off the On-Demand price."
      },
      {
        "name": "Reserved Instances",
        "description": "Save up to 72% compared to On-Demand pricing with a 1 or 3-year commitment."
      },
      {
        "name": "Savings Plans",
        "description": "Save up to 72% on compute usage with a 1 or 3-year commitment to a consistent amount of usage."
      }
    ],
    "regions": "25+ regions and 80+ availability zones worldwide.",
    "support": "Basic (free), Developer, Business, Enterprise support plans with varying response times and features. Extensive documentation, forums, and training resources."
  },
  {
    "id": "30a69dae-5939-499a-a4f5-5114797dcdb3",
    "name": "RunPod",
    "slug": "runpod",
    "description": "RunPod provides cost-effective GPU rentals with a simple interface and powerful features for AI and ML workloads.",
    "link": "https://runpod.io",
    "docsLink": "https://docs.runpod.io",
    "features": [
      {
        "title": "Secure Cloud GPUs",
        "description": "Access to a wide range of GPU types with enterprise-grade security"
      },
      {
        "title": "Pay-as-you-go",
        "description": "Only pay for the compute time you actually use"
      },
      {
        "title": "API Access",
        "description": "Programmatically manage your GPU instances via REST API"
      },
      {
        "title": "Fast cold-starts",
        "description": "Pods typically ready in 20-30 s"
      },
      {
        "title": "Hot-reload dev loop",
        "description": "SSH & VS Code tunnels built-in"
      },
      {
        "title": "Spot-to-on-demand fallback",
        "description": "Automatic migration on pre-empt"
      }
    ],
    "pros": [
      "Competitive pricing with pay-per-second billing",
      "Wide variety of GPU options",
      "Simple and intuitive interface"
    ],
    "cons": [
      "GPU availability can vary by region",
      "Some features require technical knowledge"
    ],
    "gettingStarted": [
      {
        "title": "Create an account",
        "description": "Sign up for RunPod using your email or GitHub account"
      },
      {
        "title": "Add payment method",
        "description": "Add a credit card or cryptocurrency payment method"
      },
      {
        "title": "Launch your first pod",
        "description": "Select a template and GPU type to launch your first instance"
      }
    ]
  },
  {
    "id": "d122f315-b060-4924-8726-788c28ed3905",
    "name": "Google Cloud",
    "slug": "google",
    "description": "GCP provides powerful GPU instances with flexible pricing and integration with Google's AI and machine learning tools. It's a major cloud provider known for its innovation in Kubernetes, AI/ML, and data analytics.",
    "link": "https://cloud.google.com/gpu",
    "docsLink": "https://cloud.google.com/compute/docs",
    "features": [
      {
        "title": "Compute Engine",
        "description": "Scalable virtual machines with a wide range of machine types, including GPUs."
      },
      {
        "title": "Google Kubernetes Engine (GKE)",
        "description": "Managed Kubernetes service for deploying and managing containerized applications."
      },
      {
        "title": "Cloud Functions",
        "description": "Event-driven serverless compute platform."
      },
      {
        "title": "Cloud Run",
        "description": "Fully managed serverless platform for containerized applications."
      },
      {
        "title": "Vertex AI",
        "description": "Unified ML platform for building, deploying, and managing ML models."
      },
      {
        "title": "Preemptible VMs",
        "description": "Short-lived compute instances at a significant discount, suitable for fault-tolerant workloads."
      },
      {
        "title": "Cloud Storage",
        "description": "Scalable and durable object storage."
      },
      {
        "title": "Persistent Disk",
        "description": "Block storage for Compute Engine instances."
      },
      {
        "title": "Cloud Load Balancing",
        "description": "High-performance, scalable load balancing."
      },
      {
        "title": "Virtual Private Cloud (VPC)",
        "description": "Software-defined networking for your cloud resources."
      }
    ],
    "pros": [
      "Flexible pricing options, including sustained use discounts",
      "Strong AI and machine learning tools (Vertex AI)",
      "Good integration with other Google services",
      "Cutting-edge Kubernetes implementation (GKE)",
      "Competitive pricing, especially for sustained use",
      "Strong global network infrastructure",
      "Innovative AI/ML and data analytics services"
    ],
    "cons": [
      "Limited availability in some regions compared to AWS",
      "Complexity in managing resources",
      "Support can be costly",
      "Steeper learning curve for some services"
    ],
    "gettingStarted": [
      {
        "title": "Create a Google Cloud project",
        "description": "Set up a project in the Google Cloud Console."
      },
      {
        "title": "Enable billing",
        "description": "Set up a billing account to pay for resource usage."
      },
      {
        "title": "Choose a compute service",
        "description": "Select Compute Engine, GKE, Cloud Functions, or Cloud Run based on your needs."
      },
      {
        "title": "Create and configure an instance",
        "description": "Launch a VM instance, configure a Kubernetes cluster, or deploy a function/application."
      },
      {
        "title": "Manage resources",
        "description": "Use the Cloud Console, command-line tools, or APIs to manage your resources."
      }
    ],
    "computeServices": [
      {
        "name": "Compute Engine",
        "description": "Offers customizable virtual machines running in Google's data centers.",
        "instanceTypes": [
          {
            "name": "A2",
            "description": "Based on NVIDIA A100 Tensor Core GPUs, ideal for demanding AI/ML and HPC workloads.",
            "features": [
              "Up to 16 NVIDIA A100 GPUs per instance",
              "High-speed NVLink interconnect between GPUs",
              "Suitable for large-scale model training and inference"
            ]
          },
          {
            "name": "G2",
            "description": "Powered by NVIDIA L4 GPUs, optimized for graphics-intensive applications and inference.",
            "features": [
              "Uses the NVIDIA Ada Lovelace architecture",
              "Good for graphics rendering, game streaming, and machine learning inference"
            ]
          },
          {
            "name": "T4",
            "description": "Based on NVIDIA T4 Tensor Core GPUs, suitable for a wide range of workloads, including machine learning inference and video transcoding",
            "features": [
                "Versatile performance for various applications",
                "Cost-effective for inference workloads"
            ]
          },
          {
            "name": "V100",
            "description": "Powered by NVIDIA V100 Tensor Core GPUs, designed for high-performance deep learning training and HPC.",
            "features": [
              "High performance for FP32 and FP16 workloads",
              "Suitable for complex simulations and model training"
            ]
          },
          {
            "name": "P4",
            "description": "Equipped with NVIDIA P4 GPUs, optimized for inference workloads.",
            "features": [
              "Energy-efficient for inference",
              "Good for real-time processing and video analysis"
            ]
          },
          {
            "name": "P100",
            "description": "Based on NVIDIA P100 GPUs, suitable for a variety of HPC and deep learning applications.",
            "features": [
              "Good balance of performance and cost",
              "Suitable for scientific computing and machine learning training"
            ]
          },
          {
            "name": "K80",
            "description": "Powered by NVIDIA K80 GPUs, a cost-effective option for less demanding GPU computing tasks.",
            "features": [
                "Entry-level GPU for basic deep learning and HPC workloads",
                "Lower cost compared to newer generation GPUs"
            ]
          }
        ]
      },
      {
        "name": "Google Kubernetes Engine (GKE)",
        "description": "Managed Kubernetes service for running containerized applications.",
        "features": [
          "Automated Kubernetes operations",
          "Integration with Google Cloud services",
          "Advanced cluster management features"
        ]
      },
      {
        "name": "Cloud Functions",
        "description": "Serverless compute platform for running code in response to events.",
        "features": [
          "Automatic scaling and high availability",
          "Pay only for the compute time consumed",
          "Supports multiple programming languages"
        ]
      },
      {
        "name": "Cloud Run",
        "description": "Fully managed serverless platform for deploying and scaling containerized applications.",
        "features": [
          "Runs stateless containers on a fully managed environment",
          "Automatic scaling and high availability",
          "Pay only for the resources used"
        ]
      }
    ],
    "gpuServices": [
      {
        "name": "Compute Engine GPU Instances",
        "description": "Virtual machines with attached GPUs for accelerated computing.",
        "types": [
          {
            "name": "A2",
            "gpuModel": "NVIDIA A100",
            "bestFor": "Large-scale AI training, HPC"
          },
          {
            "name": "G2",
            "gpuModel": "NVIDIA L4",
            "bestFor": "Graphics rendering, machine learning inference"
          },
          {
            "name": "T4",
            "gpuModel": "NVIDIA T4",
            "bestFor": "Machine learning inference, video transcoding"
          },
          {
            "name": "V100",
            "gpuModel": "NVIDIA V100",
            "bestFor": "Deep learning training, HPC"
          },
          {
            "name": "P4",
            "gpuModel": "NVIDIA P4",
            "bestFor": "Inference workloads, real-time processing"
          },
          {
            "name": "P100",
            "gpuModel": "NVIDIA P100",
            "bestFor": "HPC, deep learning training"
          },
          {
            "name": "K80",
            "gpuModel": "NVIDIA K80",
            "bestFor": "Entry-level deep learning, HPC"
          }
        ]
      },
      {
        "name": "Vertex AI",
        "description": "Unified machine learning platform for building, deploying, and managing ML models.",
        "features": [
          "Support for various ML frameworks",
          "Automated machine learning (AutoML)",
          "Tools for data preparation, model training, and deployment"
        ]
      }
    ],
    "pricingOptions": [
      {
        "name": "On-Demand",
        "description": "Pay for compute capacity per hour or per second, with no long-term commitments."
      },
      {
        "name": "Sustained Use Discounts",
        "description": "Automatic discounts for running instances for a significant portion of the month."
      },
      {
        "name": "Committed Use Discounts",
        "description": "Save up to 57% with a 1-year or 3-year commitment to a minimum level of resource usage."
      },
      {
        "name": "Preemptible VMs",
        "description": "Save up to 80% for fault-tolerant workloads that can be interrupted."
      }
    ],
    "regions": "35+ regions and 100+ zones worldwide.",
    "support": "Role-based (free), Standard, Enhanced and Premium support plans. Comprehensive documentation, community forums, and training resources.",
    "uniqueSellingPoints": [
      "Strong focus on Kubernetes and containerization (GKE)",
      "Cutting-edge AI and machine learning services (Vertex AI)",
      "Innovative networking infrastructure",
      "Competitive pricing, especially with sustained use discounts"
    ]
  },
  {
    "id": "11f663cd-d914-4863-9094-f293ee6421e0",
    "name": "Microsoft Azure",
    "slug": "azure",
    "description": "Azure provides comprehensive cloud computing services with strong enterprise integration, advanced AI capabilities, and a wide range of GPU options for machine learning, visualization, and high-performance computing workloads.",
    "link": "https://azure.microsoft.com/en-us/solutions/ai/",
    "docsLink": "https://learn.microsoft.com/en-us/azure/",
    "features": [
      {
        "title": "Azure AI",
        "description": "Comprehensive suite of AI services and tools for building intelligent applications"
      },
      {
        "title": "Enterprise Integration",
        "description": "Seamless integration with Microsoft ecosystem and enterprise tools"
      },
      {
        "title": "Hybrid Capabilities",
        "description": "Strong hybrid and multi-cloud support with Azure Arc"
      },
      {
        "title": "Advanced Security",
        "description": "Industry-leading security features and compliance certifications"
      },
      {
        "title": "Global Scale",
        "description": "Extensive worldwide network of data centers and edge locations"
      }
    ],
    "pros": [
      "Strong enterprise integration and support",
      "Comprehensive AI and machine learning services",
      "Advanced security and compliance features",
      "Extensive hybrid cloud capabilities",
      "Wide range of GPU options",
      "Strong .NET and Windows workload support",
      "Integrated development tools and DevOps services"
    ],
    "cons": [
      "Complex pricing and billing structure",
      "Can be expensive for certain workloads",
      "Steeper learning curve for new users",
      "Some services have limited regional availability",
      "Documentation can be fragmented"
    ],
    "gettingStarted": [
      {
        "title": "Create an Azure account",
        "description": "Sign up for Azure and get started with free credits"
      },
      {
        "title": "Set up your environment",
        "description": "Configure your subscription, resource groups, and access controls"
      },
      {
        "title": "Choose compute services",
        "description": "Select from VMs, containers, or serverless based on your needs"
      },
      {
        "title": "Deploy resources",
        "description": "Launch your first GPU-enabled instance or AI service"
      }
    ],
    "computeServices": [
      {
        "name": "Azure Virtual Machines",
        "description": "GPU-enabled VMs for various workloads",
        "instanceTypes": [
          {
            "name": "NDm A100 v4",
            "description": "Powered by NVIDIA A100 Tensor Core GPUs for AI and HPC",
            "features": [
              "Up to 8 NVIDIA A100 80GB GPUs",
              "NVIDIA NVLink interconnect",
              "400 Gb/s NVIDIA Mellanox NDR InfiniBand"
            ]
          },
          {
            "name": "NC A100 v4",
            "description": "Optimized for deep learning and HPC",
            "features": [
              "NVIDIA A100 GPUs",
              "High-performance computing and AI training",
              "PCIe-based GPU connectivity"
            ]
          },
          {
            "name": "ND A100 v4",
            "description": "For large-scale AI training and inference",
            "features": [
              "NVIDIA A100 GPUs",
              "Optimized for distributed AI workloads",
              "High-bandwidth GPU interconnect"
            ]
          }
        ]
      },
      {
        "name": "Azure Kubernetes Service (AKS)",
        "description": "Managed Kubernetes service with GPU support",
        "features": [
          "Integrated GPU node pools",
          "Automated scaling and updates",
          "DevOps integration"
        ]
      },
      {
        "name": "Azure Machine Learning",
        "description": "End-to-end ML platform with GPU acceleration",
        "features": [
          "Automated ML capabilities",
          "Integrated MLOps",
          "Distributed training support"
        ]
      }
    ],
    "gpuServices": [
      {
        "name": "GPU-Optimized Virtual Machines",
        "description": "Range of GPU-enabled VM sizes for different workloads",
        "types": [
          {
            "name": "NDm A100 v4",
            "gpuModel": "NVIDIA A100 80GB",
            "bestFor": "Large-scale AI training, HPC"
          },
          {
            "name": "NC A100 v4",
            "gpuModel": "NVIDIA A100",
            "bestFor": "Deep learning, HPC workloads"
          },
          {
            "name": "NV-series",
            "gpuModel": "NVIDIA Tesla M60",
            "bestFor": "Visualization, remote workstations"
          }
        ]
      }
    ],
    "pricingOptions": [
      {
        "name": "Pay-as-you-go",
        "description": "Flexible pricing with no upfront commitment"
      },
      {
        "name": "Reserved VM Instances",
        "description": "Save up to 72% with 1 or 3-year commitments"
      },
      {
        "name": "Spot VMs",
        "description": "Up to 90% savings for interruptible workloads"
      },
      {
        "name": "Azure Hybrid Benefit",
        "description": "Cost savings for existing Windows Server and SQL Server licenses"
      }
    ],
    "regions": "60+ regions worldwide with multiple availability zones",
    "support": "Basic, Developer, Standard, and Professional Direct support plans with 24/7 options. Extensive documentation and community resources."
  },
  {
    "name": "IBM Cloud",
    "description": "IBM Cloud provides GPU instances optimized for AI and data-intensive workloads, with a focus on enterprise solutions.",
    "pros": [
      "Strong focus on AI and data workloads",
      "Enterprise-grade support",
      "Integration with IBM's AI tools"
    ],
    "cons": [
      "Limited global presence compared to competitors",
      "Higher cost for some services",
      "Less community support"
    ],
    "link": "https://www.ibm.com/cloud/gpu",
    "slug": "ibm"
  },
  {
    "name": "Oracle Cloud",
    "description": "Oracle Cloud offers GPU instances with a focus on high-performance computing and enterprise applications.",
    "pros": [
      "Competitive pricing",
      "Strong performance for enterprise applications",
      "Good integration with Oracle products"
    ],
    "cons": [
      "Smaller ecosystem compared to AWS and GCP",
      "Limited documentation and community support",
      "Complexity in setup and management"
    ],
    "link": "https://www.oracle.com/cloud/compute/gpu.html",
    "slug": "oracle"
  },
  {
    "id": "1d434a66-bf40-40a8-8e80-d5ab48b6d27f",
    "name": "CoreWeave",
    "description": "CoreWeave is a specialized cloud provider offering GPU-accelerated infrastructure for compute-intensive workloads such as machine learning, VFX rendering, and batch processing. They provide a Kubernetes-native platform with a wide range of NVIDIA GPUs, delivering high performance at competitive prices.",
    "pros": [
      "Extensive selection of NVIDIA GPUs, including latest models",
      "Up to 35x faster and 80% less expensive than legacy cloud providers",
      "Kubernetes-native infrastructure for easy scaling and deployment",
      "Rapid deployment with ability to access thousands of GPUs in seconds",
      "Specialized support for AI, machine learning, and rendering workloads",
      "NVIDIA Elite Cloud Solutions Provider for both Compute and Visualization",
      "Fully-managed, bare metal serverless Kubernetes infrastructure"
    ],
    "cons": [
      "Primary focus on North American data centers",
      "Specialized nature may not suit all general computing needs",
      "Newer player compared to established cloud giants",
      "Learning curve for users unfamiliar with Kubernetes"
    ],
    "link": "https://www.coreweave.com/",
    "slug": "coreweave"
  },
  {
    "id": "1d434a66-bf40-40a8-8e80-d5ab48b6d27f",
    "name": "Vast.ai",
    "description": "Vast.ai is a marketplace for cloud GPU rental, connecting users to a network of GPU providers. It offers significant cost savings compared to traditional cloud services, with both on-demand and interruptible pricing models, real-time bidding, and Docker-based deployments.",
    "pros": [
      "Cost-effective (5-6X cheaper than traditional cloud services)",
      "Flexible pricing with on-demand and interruptible options",
      "Real-time bidding system for cost optimization",
      "Docker ecosystem for quick software deployment",
      "Enterprise-grade security and compliance",
      "Supports various AI and deep learning workloads",
      "CLI support for automated deployment"
    ],
    "cons": [
      "Primarily focused on Linux-based Docker instances",
      "No Windows support",
      "Limited GUI options (SSH, Jupyter, or command-only)",
      "No remote desktop functionality",
      "Performance may vary across different providers"
    ],
    "link": "https://vast.ai/",
    "slug": "vast"
  },
  {
    "id": "825cef3b-54f5-426e-aa29-c05fe3070833",
    "name": "Lambda Labs",
    "description": "Lambda Labs is an AI compute platform offering GPU cloud services, specializing in on-demand NVIDIA GPUs for AI training, fine-tuning, and inference. They provide a range of GPU instances, including access to the latest NVIDIA H100 and H200 Tensor Core GPUs.",
    "pros": [
      "Early access to latest NVIDIA GPUs (H100, H200, Blackwell)",
      "Specialized for AI workloads",
      "One-click Jupyter access",
      "Pre-installed popular ML frameworks",
      "Multi-GPU instances available (up to 8x GPUs)",
      "Developer-friendly API",
      "Offers both on-demand and reserved GPU clusters",
      "High-speed NVIDIA Quantum-2 InfiniBand networking"
    ],
    "cons": [
      "Primarily focused on AI and ML workloads",
      "Limited global data center presence compared to major cloud providers",
      "Newer player in the cloud GPU market",
      "May have higher costs for non-AI workloads"
    ],
    "link": "https://lambdalabs.com/",
    "slug": "lambda"
  },
  {
    "id": "1d434a66-bf40-40a8-8e80-d5ab48b6d27f",
    "name": "Fluidstack",
    "description": "FluidStack is a GPU cloud platform that aggregates underutilized GPUs from data centers worldwide, offering affordable and scalable computing solutions for AI training, machine learning, and rendering. They provide on-demand access to high-performance NVIDIA GPUs, including H100 and A100 models, with fully managed Kubernetes and SLURM environments.",
    "pros": [
      "Highly cost-effective (30-80% lower costs compared to major cloud providers)",
      "Large-scale GPU availability (10,000+ NVIDIA H100 GPUs deployed)",
      "Rapid deployment and scaling capabilities",
      "Fully managed infrastructure with 24/7 support",
      "Flexible options from on-demand instances to reserved clusters",
      "MLOps services included at no extra cost",
      "Wide range of GPU models available",
      "Enterprise-grade security and compliance"
    ],
    "cons": [
      "Relatively newer and smaller compared to major cloud providers",
      "Primary focus on AI and ML workloads may not suit all use cases",
      "Limited global presence compared to hyperscalers",
      "Less established brand recognition in the broader cloud market"
    ],
    "link": "https://www.fluidstack.io/",
    "slug": "fluidstack"
  },
  {
    "id": "8b1f3feb-2c2f-4983-a451-2564dccc8917",
    "name": "Genesis Cloud",
    "slug": "genesis",
    "description": "Genesis Cloud is a best-in-class AI cloud provider offering GPU solutions at scale for EnterpriseAI, GenAI, ML workloads, and rendering. They focus on providing NVIDIA-based architecture with superior cost-efficiency and performance.",
    "link": "https://www.genesiscloud.com/",
    "docsLink": "https://docs.genesiscloud.com/",
    "features": [
      {
        "title": "Enterprise AI Cloud",
        "description": "End-to-end machine learning platforms with high reliability and scalability"
      },
      {
        "title": "High Performance",
        "description": "35x more performance for LLMs, GenAI, and large multi-node trainings"
      },
      {
        "title": "EU Sovereign Cloud",
        "description": "AI workloads under EU regulations with enhanced security"
      },
      {
        "title": "Green Infrastructure",
        "description": "100% green energy powered data centers with low PUE"
      }
    ],
    "pros": [
      "80% less expensive compared to legacy cloud providers",
      "35x more performance for LLMs and GenAI workloads",
      "EU sovereign cloud compliance",
      "100% green energy infrastructure",
      "ISO27001 certified data centers",
      "Up to 100 Gbps internet connectivity",
      "99.9% guaranteed uptime",
      "Early access to latest NVIDIA GPUs (B200, GB200)"
    ],
    "cons": [
      "Limited global presence (primarily EU-focused)",
      "Newer player compared to major cloud providers",
      "Specialized focus may not suit all computing needs"
    ],
    "computeServices": [
      {
        "name": "NVIDIA GPU Instances",
        "description": "Various NVIDIA GPU options for AI and ML workloads",
        "instanceTypes": [
          {
            "name": "NVIDIA HGX H100",
            "description": "Superior AI training and inference workloads with SXM5 H100",
            "features": [
              "MLPerf benchmark-dominating GPU",
              "30x AI inference over Ampere generation",
              "3.2 Tbps InfiniBand connectivity",
              "Starting from $2.00/h per GPU"
            ]
          },
          {
            "name": "NVIDIA Blackwell Architecture",
            "description": "Next-generation AI superchip (Coming Soon)",
            "features": [
              "Up to 4x faster AI training than previous generation",
              "Up to 30x speed up in real-time LLM inference",
              "Secure AI protecting LLMs and sensitive data"
            ]
          }
        ]
      }
    ],
    "support": "Knowledge base, developer documentation, and dedicated support team",
    "regions": "Tier 3 data centers in the European Union",
    "uniqueSellingPoints": [
      "Built on NVIDIA's reference architecture",
      "Optimized for AI and ML workloads",
      "No ingress or egress fees",
      "High-bandwidth network optimized for multi-node operations"
    ]
  },
  {
    "id": "1d434a66-bf40-40a8-8e80-d5ab48b6d27f",
    "name": "Datacrunch",
    "slug": "datacrunch",
    "description": "DataCrunch.io is a Finnish cloud service provider specializing in AI and machine learning infrastructure. They offer dedicated GPU servers, fully-managed services, and on-demand access to high-performance computing resources, including advanced NVIDIA GPUs like the A100 and H200.",
    "pros": [
      "Wide range of GPU models, including latest NVIDIA H200",
      "Cost-effective compared to major cloud providers",
      "Streamlined and user-friendly interface",
      "Excellent documentation and API",
      "Flexible pricing with pay-as-you-go model",
      "Based in EU, potentially easing GDPR compliance",
      "Renewable energy-powered data centers"
    ],
    "cons": [
      "Limited global presence (primarily Europe-focused)",
      "Smaller company compared to major cloud providers",
      "Specialized focus may not suit all computing needs",
      "Fewer data center locations than larger competitors"
    ],
    "link": "https://datacrunch.io/"
  },
  {
    "id": "54cc0c05-b0e6-49b3-95fb-831b36dd7efd",
    "name": "Hyperstack",
    "slug": "hyperstack",
    "description": "Hyperstack provides GPU cloud solutions with a focus on AI and machine learning. As an NVIDIA Preferred NCP Partner, they own, operate, and optimise everything from the servers and network to the platform itself, offering enterprise-level GPU-acceleration.",
    "link": "https://www.hyperstack.cloud/",
    "docsLink": "https://www.hyperstack.cloud/documentation",
    "features": [
      {
        "title": "Managed Kubernetes",
        "description": "Automated software deployment, scaling and management"
      },
      {
        "title": "Pre-Configured Flavours",
        "description": "Optimized templates for GPU-accelerated workloads with custom flavor options"
      },
      {
        "title": "First Class API",
        "description": "Purpose-built API designed specifically for GPU cloud operations"
      },
      {
        "title": "Optimised Networking",
        "description": "Network architecture optimized for maximum GPU efficiency"
      },
      {
        "title": "Premium Storage",
        "description": "Multiple storage options including NVMe, HDD block, and HDD Shared storage"
      }
    ],
    "pros": [
      "Up to 75% more cost-effective than major cloud providers",
      "GPU-optimized ecosystem for maximum performance efficiency",
      "Easy-to-use platform with 1-click deployments",
      "100% renewable energy powered infrastructure",
      "NVIDIA Preferred NCP Partner",
      "Enterprise-grade features and support",
      "Role-based access control"
    ],
    "cons": [
      "Limited global presence (primarily Europe and North America)",
      "Niche market focus on GPU workloads",
      "Less established compared to major cloud providers"
    ],
    "gettingStarted": [
      {
        "title": "Register Account",
        "description": "Sign up for Hyperstack cloud services"
      },
      {
        "title": "Choose Configuration",
        "description": "Select from pre-configured flavors or create custom ones"
      },
      {
        "title": "Deploy Resources",
        "description": "Launch GPU instances with 1-click deployment"
      }
    ],
    "computeServices": [
      {
        "name": "GPU Instances",
        "description": "Range of NVIDIA GPU options for various workloads",
        "instanceTypes": [
          {
            "name": "NVIDIA H100 SXM",
            "description": "High-performance GPU instances for AI and ML workloads",
            "features": [
              "On-demand pricing from $3.00/hour",
              "Reserved pricing from $2.10/hour",
              "Scalable from 8 to 16,384 GPUs"
            ]
          }
        ]
      }
    ],
    "regions": "Data centers in Europe and North America",
    "support": "Human support team, documentation, and developer resources",
    "uniqueSellingPoints": [
      "100% renewably powered by hydro-energy",
      "20x more energy-efficient than traditional computing",
      "99.982% uptime guarantee",
      "Free air cooling in data centers",
      "Multi-region support"
    ]
  },
  {
    "id": "6f6f477e-c195-4403-a07a-4cf9faa65a08",
      "name": "The Cloud Minders",
      "slug": "cloud-minders",
      "description": "The Cloud Minders (TCM) offers supercompute-as-a-service, specializing in AI training and inference. They provide purpose-built AI clouds with the latest NVIDIA GPUs and industry-leading CPUs, aiming to offer more flexibility than hyperscalers and more long-term viability than GPU marketplaces. They emphasize a partnership approach, working closely with clients to optimize their AI infrastructure.",
      "link": "https://www.thecloudminders.com",
      "docsLink": null,
      "features": [
        {
          "title": "Purpose-Built AI Clouds",
          "description": "Custom solutions optimized for specific AI/ML workload needs."
        },
        {
          "title": "Bleeding Edge GPUs",
          "description": "Equipped with the latest NVIDIA GPUs, including H100 and H200."
        },
        {
          "title": "Industry Leading CPUs",
          "description": "EPYC CPUs with clock speeds over 3.0 GHz for faster processing."
        },
        {
          "title": "AI-Optimized Platform",
          "description": "Integrates smoothly with popular AI/ML frameworks and tools."
        },
        {
          "title": "NVMe Storage",
          "description": "Ultra-fast NVMe storage for handling large datasets and numerous small files."
        },
        {
          "title": "Flexible Options",
          "description": "Supports Docker containers, VMs, and bare metal servers optimized and accelerated by the latest GPUs."
        }
      ],
      "pros": [
        "Access to the latest NVIDIA GPUs like H200.",
        "Purpose-built infrastructure optimized for AI/ML workloads.",
        "Flexible deployment options (VMs, Docker, Bare Metal).",
        "Transparent pricing model with no hidden fees.",
        "Potential for workload benchmarking on H200 vs. H100.",
        "High-speed networking and super-fast storage.",
        "Strong focus on customer partnership and support."
      ],
      "cons": [
        "Specific geographic availability not explicitly stated.",
        "May be less established compared to major hyperscalers.",
        "Details on specific data center certifications (beyond SOC 1 Type 2) are not provided."
      ],
      "gettingStarted": [
        {
          "title": "Contact TCM",
          "description": "Reach out to The Cloud Minders to discuss your specific AI infrastructure needs."
        },
        {
          "title": "Benchmark Workload (Optional)",
          "description": "Sign up to benchmark your workload on an 8x H200 server."
        },
        {
          "title": "Choose Deployment Option",
          "description": "Select from VM images, Docker containers, or bare metal GPUs based on your requirements."
        }
      ],
      "computeServices": [
        {
          "name": "GPU Instances",
          "description": "Variety of NVIDIA GPU options for different AI/ML tasks.",
          "instanceTypes": [
            {
              "name": "Nvidia H200 SXM",
              "description": "High-performance GPU for large AI models.",
              "features": [
                "141GB vRAM",
                "4.8TB/s memory bandwidth",
                "On-demand pricing starting at $4.85/GPU/Hr"
              ]
            },
            {
              "name": "Nvidia H100 SXM",
              "description": "High-performance GPU for advanced AI and vision tasks",
              "features": [
                "80GB vRAM",
                "On-demand pricing starting at $4.52/Hr"
              ]
            },
            {
              "name": "Nvidia H100 NVL",
              "description": "Optimized for high-throughput inference and complex NLP tasks.",
              "features": [
                "94GB vRAM",
                "On-demand pricing starting at $4.05/Hr"
              ]
            },
            {
              "name": "RTX A5000",
              "description": "Suitable for object detection, creative AI tasks, and text-to-image generation.",
              "features": [
                "24GB vRAM",
                "On-demand pricing starting at $0.55/Hr"
              ]
            },
             {
              "name": "RTX 4000 Ada",
              "description": "Good for Image segmentation, facial recognition, medical imaging",
              "features": [
                "20GB vRAM",
                "On-demand pricing starting at $0.55/Hr"
              ]
            },
            {
              "name": "RTX A4000",
              "description": "Compact inference, real-time audio processing, mobile AI",
              "features": [
                "16GB vRAM",
                "On-demand pricing starting at $0.40/Hr"
              ]
            },
            {
              "name": "V100",
              "description": "Image classification, sequential data analysis, NLP fine-tuning",
              "features": [
                "16GB vRAM",
                "On-demand pricing starting at $0.24/Hr"
              ]
            }
          ]
        }
      ],
      "regions": "Data center with SOC 1 Type 2 certification, high-speed connectivity, fault-tolerant storage, and round-the-clock security.",
      "support": "Remote support available. Partnership approach with direct team interaction.",
      "uniqueSellingPoints": [
        "Supercompute as a Service tailored for AI training and inference.",
        "Access to the latest NVIDIA H200 GPUs.",
        "Transparent pricing with no hidden fees.",
        "Option to benchmark workloads on cutting-edge hardware.",
        "Best-in-class data center infrastructure with reliability and security."
      ]    
  },
  {
    "id": "c58cd5f6-4bbc-454a-abbf-fad2b94180c6",
    "name": "Paperspace",
    "slug": "paperspace",
    "description": "Paperspace, a part of DigitalOcean, is a cloud computing platform designed for AI/ML developers, offering a suite of products including interactive Jupyter notebooks (Gradient), virtual machines (Core), and an MLOps platform for building, training, and deploying machine learning models. They provide access to a wide range of NVIDIA GPUs with a focus on simplicity and ease of use.",
    "link": "https://www.paperspace.com/",
    "docsLink": "https://docs.digitalocean.com/products/paperspace/",
    "features": [
      {
        "title": "Gradient Notebooks",
        "description": "Interactive Jupyter notebooks with a free tier, pre-configured templates, and access to powerful GPUs."
      },
      {
        "title": "Gradient Deployments",
        "description": "Serve machine learning models as scalable API endpoints."
      },
      {
        "title": "Core Machines",
        "description": "High-performance virtual machines with a wide variety of NVIDIA GPUs for demanding workloads."
      },
      {
        "title": "Team Collaboration",
        "description": "Features for teams to collaborate on projects, including shared drives and SSO."
      },
      {
        "title": "Persistent Storage",
        "description": "Offers persistent storage that can be shared across different machines and notebooks."
      },
      {
        "title": "API and CLI",
        "description": "Programmatic access to the Paperspace platform to automate workflows."
      }
    ],
    "pros": [
      "User-friendly interface and easy to get started",
      "Wide range of NVIDIA GPU options",
      "Free GPU and CPU plans for notebooks",
      "Pay-per-second billing model",
      "Comprehensive MLOps platform (Gradient)",
      "Strong community forum and extensive documentation"
    ],
    "cons": [
      "Limited data center regions (US and Europe)",
      "Some user reports of inconsistent customer support",
      "Availability of high-end multi-GPU instances can be limited",
      "The platform is undergoing changes after being acquired by DigitalOcean"
    ],
    "gettingStarted": [
      {
        "title": "Create an Account",
        "description": "Sign up for a Paperspace account. You can start with a free plan."
      },
      {
        "title": "Choose a Product",
        "description": "Select the product that best fits your needs, such as Gradient Notebooks for interactive development or Core Machines for more control."
      },
      {
        "title": "Select a Template and Machine",
        "description": "Choose a pre-configured template for your desired framework and select a GPU or CPU instance."
      },
      {
        "title": "Start Working",
        "description": "Launch your machine or notebook and begin building, training, or deploying your AI applications."
      }
    ],
    "computeServices": [
      {
        "name": "Core GPU Instances",
        "description": "Virtual machines with a wide range of NVIDIA GPUs for various workloads.",
        "instanceTypes": [
          {
            "name": "NVIDIA H100",
            "description": "Top-tier GPU for large-scale AI model training and inference.",
            "features": [
              "80GB of VRAM",
              "PCIe interface",
              "Available in single and multi-GPU configurations"
            ]
          },
          {
            "name": "NVIDIA A100",
            "description": "Powerful GPU for AI, data analytics, and HPC.",
            "features": [
              "40GB and 80GB VRAM options",
              "SXM4 and PCIe interconnects",
              "Available in multi-GPU configurations"
            ]
          },
          {
            "name": "NVIDIA A6000",
            "description": "Professional GPU for graphics-intensive workloads, rendering, and AI.",
            "features": [
              "48GB of VRAM",
              "Suitable for professional visualization and AI",
              "Available in multi-GPU configurations"
            ]
          },
          {
            "name": "NVIDIA A5000 / A4000",
            "description": "Cost-effective GPUs for a variety of AI and graphics workloads.",
            "features": [
              "24GB (A5000) and 16GB (A4000) of VRAM",
              "Balanced performance for development and smaller-scale training"
            ]
          },
          {
            "name": "NVIDIA RTX 5000 / RTX 4000",
            "description": "Quadro GPUs suitable for professional graphics and some ML tasks.",
            "features": [
              "16GB (RTX 5000) and 8GB (RTX 4000) of VRAM",
              "Real-time ray tracing capabilities"
            ]
          }
        ]
      },
      {
        "name": "Gradient Notebooks",
        "description": "Managed Jupyter notebooks for interactive development and experimentation.",
        "features": [
          "Free CPU and GPU tiers",
          "1-click launch with pre-configured templates",
          "Persistent storage for your projects",
          "Collaboration features for teams"
        ]
      },
      {
        "name": "Gradient Deployments",
        "description": "A serverless product for deploying trained models as REST APIs.",
        "features": [
          "Scalable and managed infrastructure",
          "Integration with Gradient Notebooks and Workflows",
          "Real-time monitoring of deployed models"
        ]
      }
    ],
    "regions": "Data centers are located in the US (Secaucus, NJ and Santa Clara, CA) and Europe (Amsterdam, NL).",
    "support": "Support is available through a community forum, extensive documentation, and a support ticket system.",
    "uniqueSellingPoints": [
      "Simplicity and developer-focused user experience",
      "A comprehensive MLOps platform (Gradient) for the entire ML lifecycle",
      "Offers a free tier with GPU access for notebooks",
      "Strong community and a showcase of public projects",
      "Now part of the DigitalOcean ecosystem"
    ]
  },
  {
    "id": "ee80fbec-5f7f-4f44-b6bb-d70042b0a799",
    "name": "TensorWave",
    "slug": "tensorwave",
    "description": "TensorWave is a cloud provider specializing in AI and HPC workloads, leveraging AMD Instinct accelerators. They offer scalable, memory-optimized infrastructure designed for demanding AI tasks, including training, fine-tuning, and inference. TensorWave aims to provide an alternative to Nvidia-based platforms, with a focus on performance, scalability, and a better price-to-performance ratio.",
    "link": "https://tensorwave.com/",
    "docsLink": "https://docs.tensorwave.com/",
    "features": [
      {
        "title": "AMD Instinct Accelerators",
        "description": "Powered by AMD Instinctâ„¢ Series GPUs for high-performance AI workloads."
      },
      {
        "title": "High VRAM GPUs",
        "description": "Offers instances with 192GB of VRAM per GPU, ideal for large models."
      },
      {
        "title": "Bare Metal & Kubernetes",
        "description": "Provides both bare metal servers for maximum control and managed Kubernetes for orchestration."
      },
      {
        "title": "Direct Liquid Cooling",
        "description": "Utilizes direct liquid cooling to reduce data center energy costs and improve efficiency."
      },
      {
        "title": "High-Speed Network Storage",
        "description": "Features high-speed network storage to support demanding AI pipelines."
      },
      {
        "title": "ROCm Software Ecosystem",
        "description": "Leverages the AMD ROCm open software ecosystem to avoid vendor lock-in."
      }
    ],
    "pros": [
      "Specialized in high-performance AMD GPUs",
      "Offers GPUs with large VRAM (192GB)",
      "Claims better price-to-performance than competitors",
      "Provides 'white-glove' onboarding and support",
      "Utilizes an open-source software stack (ROCm)",
      "Offers bare metal access for greater control"
    ],
    "cons": [
      "A newer and less established company (founded in 2023)",
      "Exclusively focused on AMD, which may be a limitation for some users",
      "Limited publicly available information on pricing",
      "A smaller ecosystem when compared to major cloud providers"
    ],
    "gettingStarted": [
      {
        "title": "Request Access",
        "description": "Sign up on the TensorWave website to get access to their platform."
      },
      {
        "title": "Choose a Service",
        "description": "Select between Bare Metal servers or a managed Kubernetes cluster."
      },
      {
        "title": "Follow Quickstarts",
        "description": "Utilize the documentation and quick-start guides for PyTorch, Docker, Kubernetes, and other tools."
      },
      {
        "title": "Deploy Your Model",
        "description": "Deploy your AI model for training, fine-tuning, or inference."
      }
    ],
    "computeServices": [
      {
        "name": "AMD GPU Instances",
        "description": "Bare metal servers and managed Kubernetes clusters with AMD Instinct GPUs.",
        "instanceTypes": [
          {
            "name": "AMD Instinct MI300X",
            "description": "High-performance GPU with 192GB of HBM3 memory, suitable for large language models and generative AI.",
            "features": [
              "192GB of HBM3 memory",
              "Ideal for large-scale AI model training and inference",
              "High-speed interconnects"
            ]
          },
          {
            "name": "AMD Instinct MI325X",
            "description": "Next-generation accelerator for AI and HPC workloads.",
            "features": [
              "Enhanced performance for AI and scientific computing",
              "Advanced memory architecture"
            ]
          },
          {
            "name": "AMD Instinct MI355X",
            "description": "Cutting-edge GPU built on the 4th Gen AMD CDNA architecture with 288GB of HBM3E memory.",
            "features": [
              "288GB of HBM3E memory",
              "Optimized for generative AI training and inference",
              "High-density computing with advanced cooling"
            ]
          }
        ]
      },
      {
        "name": "Managed Kubernetes",
        "description": "Kubernetes clusters for orchestrated AI workloads.",
        "features": [
          "Scalable from 8 to 1024 GPUs",
          "Interconnected with 3.2TB/s RoCE v2 networking"
        ]
      },
      {
        "name": "Inference Platform (Manifest)",
        "description": "An enterprise inference platform designed for larger context windows and reduced latency.",
        "features": [
          "Accelerated reasoning",
          "Secure and private data storage"
        ]
      }
    ],
    "regions": "Primary data center and headquarters are located in Las Vegas, Nevada. The company is building the largest AMD-specific AI training cluster in North America.",
    "support": "Offers 'white-glove' onboarding and support, extensive documentation, and a company blog.",
    "uniqueSellingPoints": [
      "Exclusive focus on AMD Instinct GPUs",
      "First-to-market with the latest AMD Instinct models",
      "Building the largest AMD-specific AI training cluster in North America",
      "Emphasis on an open-source software stack (ROCm) to prevent vendor lock-in",
      "High-memory GPUs (192GB) as a standard offering"
    ]
  },
  {
    "id": "c45c33ad-24c9-4ad7-ac37-ca0e30e63434",
    "name": "Crusoe",
    "slug": "crusoe",
    "description": "Crusoe Cloud is a cloud computing platform that leverages stranded and wasted energy sources, such as flare gas, to power its data centers, reducing carbon emissions and providing sustainable computing resources. They offer high-performance computing solutions for AI, machine learning, and scientific research, while maintaining a focus on environmental sustainability.",
    "link": "https://www.crusoe.com/",
    "docsLink": "https://docs.crusoecloud.com/",
    "features": [
      {
        "title": "Sustainable Computing",
        "description": "Powered by stranded and wasted energy sources to reduce carbon emissions"
      },
      {
        "title": "Fast Spin Up",
        "description": "Machines are deployed quickly when they are launched"
      },
      {
        "title": "Persistent Storage",
        "description": "Disk storage that can be used across multiple instances"
      },
      {
        "title": "SXM Support",
        "description": "Provides instances with NVIDIA SXM GPU interconnects"
      },
      {
        "title": "SLA Guarantee",
        "description": "Provider offers an SLA on uptime and performance"
      }
    ],
    "pros": [
      "Great GPU availability for on-demand use",
      "Affordable pricing for GPU instances",
      "Environmentally sustainable approach using stranded energy",
      "SLA guarantee on uptime and performance",
      "Lowest market price for A100_80G GPUs",
      "Fast instance deployment"
    ],
    "cons": [
      "Limited GPU variety (primarily A100, A100_80G, and L40S)",
      "Regional focus rather than global presence",
      "Newer player in the cloud GPU market",
      "Limited GPU interconnect options compared to some competitors"
    ],
    "gettingStarted": [
      {
        "title": "Create an account",
        "description": "Sign up for Crusoe Cloud services through their website"
      },
      {
        "title": "Select GPU instance",
        "description": "Choose from available GPU types (A100, A100_80G, or L40S)"
      },
      {
        "title": "Configure storage",
        "description": "Set up persistent storage options for your workloads"
      },
      {
        "title": "Launch instance",
        "description": "Deploy your instance with fast spin-up times"
      }
    ],
    "computeServices": [
      {
        "name": "GPU Instances",
        "description": "High-performance GPU instances powered by NVIDIA GPUs",
        "instanceTypes": [
          {
            "name": "A100",
            "description": "40GB NVIDIA A100 GPU instances for AI and ML workloads",
            "features": [
              "Limited availability",
              "Cost-effective pricing",
              "Suitable for deep learning and HPC workloads"
            ]
          },
          {
            "name": "A100_80G",
            "description": "80GB NVIDIA A100 GPU instances for memory-intensive AI workloads",
            "features": [
              "High availability",
              "Lowest market price",
              "Ideal for large model training and inference"
            ]
          },
          {
            "name": "L40S",
            "description": "NVIDIA L40S GPU instances for AI and graphics workloads",
            "features": [
              "High availability",
              "Competitive pricing",
              "Good balance of performance and cost"
            ]
          },
          {
            "name": "H200",
            "description": "Recently added NVIDIA H200 GPU instances for cutting-edge AI workloads",
            "features": [
              "On-demand availability",
              "State-of-the-art performance",
              "Ideal for large language models and advanced AI research"
            ]
          }
        ]
      },
      {
        "name": "Reserved Clusters",
        "description": "Large-scale reserved GPU clusters for enterprise and research workloads",
        "features": [
          "Custom node configurations",
          "Flexible interconnect options",
          "Long-term reservation for consistent availability"
        ]
      }
    ],
    "regions": "Strategically located data centers in low-cost energy areas of the United States",
    "support": "Documentation, SOC II certified infrastructure",
    "uniqueSellingPoints": [
      "Environmentally sustainable cloud computing using stranded energy sources",
      "Lowest market price for A100_80G GPUs",
      "Founded in 2018 with $350M Series C funding",
      "Integration with Shadeform for console and API access",
      "Focuses on balancing performance, availability, and environmental impact"
    ]
  },
  {
    "id": "b046d087-96e5-4bd0-9c96-060164cf9a04",
    "name": "Vultr",
    "slug": "vultr",
    "description": "Vultr offers global access to the latest AMD and NVIDIA GPUs for AI/ML, AR/VR, high-performance computing, VDI/CAD, and more, available on demand either as virtual machines or bare metal across 32 worldwide data center regions.",
    "link": "https://www.vultr.com/products/cloud-gpu/",
    "docsLink": "https://www.vultr.com/docs/",
    "features": [
      {
        "title": "AMD and NVIDIA GPU Options",
        "description": "Access to diverse GPU options including AMD Instinct and NVIDIA Tensor Core GPUs"
      },
      {
        "title": "Global Availability",
        "description": "Deploy GPU resources across 32 cloud data center regions worldwide"
      },
      {
        "title": "Kubernetes Support",
        "description": "Vultr Kubernetes Engine for GPU-accelerated containerized workloads"
      },
      {
        "title": "Serverless Inference",
        "description": "Deploy and scale GenAI models quickly with Vultr Serverless Inference"
      },
      {
        "title": "Virtual Machines and Bare Metal",
        "description": "Choose between GPU-accelerated VMs or dedicated bare metal servers"
      },
      {
        "title": "Global Content Delivery",
        "description": "Accelerate content delivery across six continents with Vultr CDN"
      }
    ],
    "pros": [
      "Wide range of AMD and NVIDIA GPU options",
      "Extensive global network (32 data center regions)",
      "Both VM and bare metal deployment options",
      "Kubernetes and containerization support",
      "NVIDIA Preferred Cloud Partner status",
      "Simplified driver setup and licensing",
      "API and Terraform integration"
    ],
    "cons": [
      "Medium GPU availability compared to some specialized providers",
      "Less established in the GPU market compared to major hyperscalers",
      "Limited documentation specific to GPU workloads"
    ],
    "gettingStarted": [
      {
        "title": "Create an account",
        "description": "Sign up for a free Vultr account"
      },
      {
        "title": "Select GPU instance",
        "description": "Choose from AMD or NVIDIA GPU options based on your workload"
      },
      {
        "title": "Choose deployment type",
        "description": "Select between virtual machine or bare metal deployment"
      },
      {
        "title": "Configure and launch",
        "description": "Set up networking, storage, and security options before launching"
      }
    ],
    "computeServices": [
      {
        "name": "NVIDIA GPU Instances",
        "description": "Virtual machines and bare metal servers with NVIDIA GPUs",
        "instanceTypes": [
          {
            "name": "NVIDIA GH200 Grace Hopper",
            "description": "Superchip delivering breakthrough acceleration for large-scale AI, model training, and inference",
            "features": [
              "Cutting-edge performance for AI/ML workloads",
              "Ideal for large language models",
              "High-speed interconnects"
            ]
          },
          {
            "name": "NVIDIA H100 & H200",
            "description": "Tensor Core GPUs for advanced AI, data analytics, and HPC workloads",
            "features": [
              "Unprecedented acceleration for AI workloads",
              "Suitable for complex simulations",
              "Latest Tensor Core technology"
            ]
          },
          {
            "name": "NVIDIA A100",
            "description": "Tensor Core GPU enabling scientific simulation, data analytics, and AI",
            "features": [
              "High performance for research applications",
              "Multi-instance GPU capability",
              "Versatile for diverse workloads"
            ]
          },
          {
            "name": "NVIDIA L40S",
            "description": "Combining AI compute with graphics and media acceleration",
            "features": [
              "Balanced performance for AI and graphics",
              "Suitable for media workloads",
              "Next-generation data center applications"
            ]
          },
          {
            "name": "NVIDIA A40",
            "description": "Professional graphics with powerful compute and AI capabilities",
            "features": [
              "Designed for creative and scientific challenges",
              "Balanced compute and graphics performance",
              "Professional visualization support"
            ]
          },
          {
            "name": "NVIDIA A16",
            "description": "GPU for virtual desktops and workstations",
            "features": [
              "Optimized for virtual desktop infrastructure",
              "Support for remote work solutions",
              "Efficient multi-user performance"
            ]
          }
        ]
      },
      {
        "name": "AMD GPU Instances",
        "description": "Computing infrastructure powered by AMD Instinct accelerators",
        "instanceTypes": [
          {
            "name": "AMD Instinct MI325X & MI300X",
            "description": "Setting new standards for powerful and efficient AI and HPC deployments",
            "features": [
              "Advanced accelerators for AI workloads",
              "High-performance computing capabilities",
              "Energy-efficient design"
            ]
          }
        ]
      },
      {
        "name": "Vultr Kubernetes Engine",
        "description": "Managed Kubernetes service for GPU-accelerated containerized applications",
        "features": [
          "GPU-accelerated Kubernetes clusters",
          "Global deployment options",
          "Simplified container orchestration",
          "Support for resource-intensive workloads"
        ]
      },
      {
        "name": "Vultr Serverless Inference",
        "description": "Deploy and scale GenAI models efficiently",
        "features": [
          "Quick deployment of AI models",
          "Efficient scaling",
          "Support for proprietary data or trained models",
          "Global acceleration"
        ]
      }
    ],
    "regions": "32 global cloud data center regions across North America, South America, Europe, Asia, Africa, and Australia",
    "support": "Documentation, community forums, support tickets, and dedicated customer support",
    "uniqueSellingPoints": [
      "Partnership with both AMD and NVIDIA",
      "NVIDIA Preferred Partner status",
      "Extensive global network of data centers",
      "Simplified GPU infrastructure setup",
      "Flexible deployment options (VM or bare metal)",
      "Integration with Vultr's broader cloud ecosystem"
    ]
  },
  {
    "id": "5cf897be-8662-4404-9c3b-d4938fb8fa71",
    "name": "Voltage Park",
    "slug": "voltage",
    "description": "Voltage Park is a U.S.-based GPU cloud provider offering scalable bare metal clusters with high availability across six Tier 3+ data centers. Founded in 2023, Voltage Park specializes in providing NVIDIA HGX H100 GPUs for AI and high-performance computing workloads.",
    "link": "https://www.voltagepark.com/",
    "docsLink": null,
    "features": [
      {
        "title": "High-Performance Hardware",
        "description": "NVIDIA HGX H100 GPUs in Dell PowerEdge XE9680 servers with 1TB RAM and v52 CPUs"
      },
      {
        "title": "Tier 3+ Data Centers",
        "description": "Six U.S.-based data centers with redundancy, availability, and reliability across power, cooling, network, and security"
      },
      {
        "title": "Blazing-Fast Network",
        "description": "NVIDIA Quantum-2 InfiniBand network with up to 3,200Gbps of aggregate bandwidth for high-speed communication"
      },
      {
        "title": "Bare Metal Access",
        "description": "Direct hardware access for maximum performance without virtualization overhead"
      },
      {
        "title": "Shadeform Integration",
        "description": "Integrated with Shadeform for console and API access"
      },
      {
        "title": "Advanced Security",
        "description": "Top-tier firewalls and comprehensive security protocols including encryption, access controls, and regular audits"
      }
    ],
    "pros": [
      "Great GPU availability for on-demand use",
      "Transparent pricing with no hidden costs",
      "Fast deployment (spin up nodes in 15 minutes)",
      "Bare metal access for maximum performance",
      "Exceptional customer service and support",
      "NVIDIA Cloud Partner status",
      "Scalable clusters from 64 to 8,176 GPUs"
    ],
    "cons": [
      "U.S.-only regions (limited global presence)",
      "Low GPU variety (primarily H100s)",
      "No persistent storage support",
      "Relatively new provider (founded 2023)"
    ],
    "gettingStarted": [
      {
        "title": "Create an account",
        "description": "Sign up for Voltage Park services through their website"
      },
      {
        "title": "Choose deployment option",
        "description": "Select between on-demand access or long-term reservation"
      },
      {
        "title": "Configure your cluster",
        "description": "Specify the number of GPUs and networking requirements"
      },
      {
        "title": "Deploy and access",
        "description": "Launch your cluster and access via SSH or preferred tools"
      }
    ],
    "computeServices": [
      {
        "name": "On-Demand GPU Access",
        "description": "Self-serve GPU instances available in minutes with no long-term contracts",
        "instanceTypes": [
          {
            "name": "NVIDIA HGX H100",
            "description": "High-performance GPU instances for AI and ML workloads",
            "features": [
              "Spin up in 15 minutes",
              "No long-term commitment required",
              "Ideal for bursts and experimentation"
            ]
          },
          {
            "name": "NVIDIA H200",
            "description": "Latest generation H200 GPUs available on-demand",
            "features": [
              "Recently added to their offering",
              "High-performance for cutting-edge AI workloads",
              "Limited availability"
            ]
          }
        ]
      },
      {
        "name": "Reserved GPU Clusters",
        "description": "Long-term GPU reservations with favorable payment terms",
        "features": [
          "12+ month contracts",
          "Friendly payment terms",
          "Priority access to resources",
          "Ideal for sustained, high-priority projects"
        ]
      }
    ],
    "regions": "Six Tier 3+ designed data centers across the United States",
    "support": "Top-tier support in partnership with Penguin, helping customers set up, optimize, and scale resources effectively",
    "uniqueSellingPoints": [
      "24,000 NVIDIA H100 Tensor Core GPUs in their fleet",
      "InfiniBand clusters supporting up to 8,176 GPUs",
      "3200 Gbps of aggregate bandwidth with NVIDIA Quantum-2 InfiniBand",
      "SOC II certified infrastructure",
      "Founded by Jed McCaleb with $500M in funding"
    ]
  }
]