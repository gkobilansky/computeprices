name: Verify Provider Data

on:
  schedule:
    # Run weekly on Mondays at 9:00 AM UTC
    - cron: '0 9 * * 1'
  workflow_dispatch:
    inputs:
      provider:
        description: 'Specific provider slug to verify (leave empty for auto-rotation)'
        required: false
        type: string

permissions:
  contents: write
  pull-requests: write
  id-token: write

jobs:
  verify-provider:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 9

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Determine provider to verify
        id: provider
        env:
          PROVIDER_INPUT: ${{ github.event.inputs.provider }}
        run: |
          if [ -n "$PROVIDER_INPUT" ]; then
            # Validate provider slug format (lowercase alphanumeric with hyphens only)
            if ! echo "$PROVIDER_INPUT" | grep -qE '^[a-z0-9-]+$'; then
              echo "Error: Invalid provider slug format. Must be lowercase alphanumeric with hyphens only."
              exit 1
            fi
            echo "slug=$PROVIDER_INPUT" >> $GITHUB_OUTPUT
          else
            # Auto-rotate: pick provider based on week number
            WEEK=$(date +%V)
            PROVIDERS=$(ls data/providers/*.json | xargs -n1 basename | sed 's/.json//' | sort)
            PROVIDER_COUNT=$(echo "$PROVIDERS" | wc -l)
            INDEX=$((WEEK % PROVIDER_COUNT))
            PROVIDER=$(echo "$PROVIDERS" | sed -n "$((INDEX + 1))p")
            echo "slug=$PROVIDER" >> $GITHUB_OUTPUT
            echo "Auto-selected provider for week $WEEK: $PROVIDER"
          fi

      - name: Verify provider file exists
        env:
          PROVIDER_SLUG: ${{ steps.provider.outputs.slug }}
        run: |
          if [ ! -f "data/providers/${PROVIDER_SLUG}.json" ]; then
            echo "Error: Provider file not found: data/providers/${PROVIDER_SLUG}.json"
            exit 1
          fi

      - name: Install Playwright browsers
        run: npx playwright install --with-deps chromium

      - name: Scrape provider website
        id: scrape
        env:
          PROVIDER_SLUG: ${{ steps.provider.outputs.slug }}
        run: |
          echo "ðŸ” Scraping provider: ${PROVIDER_SLUG}"
          node scripts/scrape-provider-with-playwright.js ${PROVIDER_SLUG}

          # Check if scraping succeeded
          if [ ! -f "scraped-data.json" ]; then
            echo "âŒ Error: Scraping failed - no output file generated"
            exit 1
          fi

          echo "âœ… Scraping completed successfully"

      - name: Analyze scraped data with Claude
        id: claude
        env:
          PROVIDER_SLUG: ${{ steps.provider.outputs.slug }}
        uses: anthropics/claude-code-action@beta
        with:
          mode: agent
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}
          allowed_tools: Read,Edit,Glob,Grep
          direct_prompt: |
            Verify and update provider data for: ${{ env.PROVIDER_SLUG }}

            ## Your Task

            We've scraped the provider's website and saved the results to `scraped-data.json`.
            Your job is to compare this fresh web data with our current provider file and update it if needed.

            ## Step 1: Read the Scraped Data

            First, read `scraped-data.json` to see what we found on their website.
            This file contains:
            - Content from their home page
            - Content from their pricing page (if found)
            - Content from their docs page (if found)
            - Content from their features page (if found)
            - GPU mentions, features, pricing info extracted from each page

            ## Step 2: Read Current Provider Data

            Read these files:
            1. `data/providers/PROVIDER_DATA_GUIDELINES.md` - Our standards for provider data
            2. `data/providers/${{ env.PROVIDER_SLUG }}.json` - Current provider data

            ## Step 3: Compare and Identify Issues

            Compare the scraped data with the current JSON file. Look for:

            **Company Information:**
            - Is the company name still correct?
            - Is the tagline accurate or outdated?
            - Is the description accurate?
            - Is the category classification still appropriate?

            **URLs:**
            - Are the website URLs correct?
            - Should we add missing `docsLink` or `pricing_page` if we found them?

            **Features & Services:**
            - Are there new features mentioned on the website that aren't in our data?
            - Are the pros/cons still accurate?
            - Are GPU model offerings up to date?

            **Missing Fields:**
            - According to PROVIDER_DATA_GUIDELINES.md, what recommended fields are missing?
            - Can we populate them from the scraped data?

            ## Step 4: Update Provider File (If Needed)

            If you found discrepancies or missing information:
            - Use Edit tool to update `data/providers/${{ env.PROVIDER_SLUG }}.json`
            - Be conservative - only change what's clearly wrong or add missing information
            - Follow PROVIDER_DATA_GUIDELINES.md for structure and content standards
            - Preserve JSON formatting (2-space indent)
            - **Do NOT change the UUID (id field)**
            - **Do NOT change the slug**

            If the current data is accurate and complete: Make no changes

            ## Step 5: Provide Detailed Summary

            Output a comprehensive summary including:
            - **Pages scraped:** List the URLs that were successfully scraped (from scraped-data.json)
            - **What you verified as accurate:** Specific claims from our JSON that match the scraped data
            - **What you changed and why:** Each change with supporting evidence from the scraped data
            - **Missing information:** Anything we should add but couldn't determine from scraped data
            - **Confidence level:** High/Medium/Low with justification

            ## Important Constraints
            - Do NOT change the provider's UUID (id field)
            - Do NOT change the slug
            - Preserve JSON formatting (2-space indent)
            - Only make factual corrections backed by scraped data
            - Follow PROVIDER_DATA_GUIDELINES.md for content standards
            - Do NOT invent information not present in the scraped data

      - name: Check for changes
        id: changes
        env:
          PROVIDER_SLUG: ${{ steps.provider.outputs.slug }}
        run: |
          if git diff --quiet "data/providers/${PROVIDER_SLUG}.json"; then
            echo "has_changes=false" >> $GITHUB_OUTPUT
            echo "No changes detected for ${PROVIDER_SLUG}"
          else
            echo "has_changes=true" >> $GITHUB_OUTPUT
            echo "Changes detected for ${PROVIDER_SLUG}"
            git diff "data/providers/${PROVIDER_SLUG}.json"
          fi

      - name: Create Pull Request
        if: steps.changes.outputs.has_changes == 'true'
        env:
          PROVIDER_SLUG: ${{ steps.provider.outputs.slug }}
          CLAUDE_CONCLUSION: ${{ steps.claude.outputs.conclusion }}
        # Pinned to v6 SHA for supply chain security
        uses: peter-evans/create-pull-request@c5a7806660adbe173f04e3e038b0ccdcd758773c
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          commit-message: "chore: update provider data for ${{ env.PROVIDER_SLUG }}"
          title: "Update provider data: ${{ env.PROVIDER_SLUG }}"
          body: |
            ## Provider Data Update

            This PR was automatically generated by the weekly provider verification workflow.

            **Provider:** ${{ env.PROVIDER_SLUG }}

            ### Changes

            Please review the changes to `data/providers/${{ env.PROVIDER_SLUG }}.json` below.

            ### Verification Summary

            ${{ env.CLAUDE_CONCLUSION || 'See workflow logs for details.' }}

            ---

            **Note:** The database will be automatically synced when this PR is merged to main via the `sync-providers.yml` workflow.

            *This PR was created automatically by Claude Code. Please review the changes carefully before merging.*
          branch: update-provider-${{ env.PROVIDER_SLUG }}
          delete-branch: true
          labels: |
            automated
            provider-data
